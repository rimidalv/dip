{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Training a Neural Network using Augmentor and Keras\n",
    "\n",
    "In this notebook, we will train a simple convolutional neural network on the MNIST dataset using Augmentor to augment images on the fly using a generator.\n",
    "\n",
    "## Import Required Libraries\n",
    "\n",
    "We start by making a number of imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: GeForce GTX TITAN X (CNMeM is enabled with initial size: 90.0% of memory, cuDNN not available)\n"
     ]
    }
   ],
   "source": [
    "import Augmentor\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a Convolutional Neural Network\n",
    "\n",
    "Once the libraries have been imported, we define a small convolutional neural network. See the Keras documentation for details of this network: <https://github.com/fchollet/keras/blob/master/examples/mnist_cnn.py> \n",
    "\n",
    "It is a three layer deep neural network, consisting of 2 convolutional layers and a fully connected layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "input_shape = (28, 28, 1)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once a network has been defined, you can compile it so that the model is ready to be trained with data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can view a summary of the network using the `summary()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 24, 24, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               1179776   \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 1,199,882\n",
      "Trainable params: 1,199,882\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Augmentor to Scan Directory for Data\n",
    "\n",
    "Now we will use Augmentor to scan a directory containing our data that we will eventually feed into the neural network in order to train it. \n",
    "\n",
    "When you point a pipeline to a directory, it will scan each subdirectory and treat each subdirectory as a class for your machine learning problem. \n",
    "\n",
    "For example, within the directory `mnist`, there are subdirectories for each digit:\n",
    "\n",
    "```\n",
    "mnist/\n",
    "├── 0/\n",
    "│   ├── 0001.png\n",
    "│   ├── 0002.png\n",
    "│   ├── ...\n",
    "│   └── 5985.png\n",
    "├── 1/\n",
    "│   ├── 0001.png\n",
    "│   ├── 0002.png\n",
    "│   ├── ...\n",
    "│   └── 6101.png\n",
    "├── 2/\n",
    "│   ├── 0000.png\n",
    "│   ├── 0001.png\n",
    "│   ├── ...\n",
    "│   └── 5801.png\n",
    "│ ...\n",
    "├── 9/\n",
    "│   ├── 0001.png\n",
    "│   ├── 0002.png\n",
    "│   ├── ...\n",
    "│   └── 6001.png\n",
    "└\n",
    "```\n",
    "\n",
    "The directory `0` contains all the images corresponding to the 0 class.\n",
    "\n",
    "To do this, we instantiate a pipeline object in the `mnist` parent directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialised with 60000 image(s) found.\n",
      "Output directory set to /home/marcus/Documents/mnist/train/output."
     ]
    }
   ],
   "source": [
    "p = Augmentor.Pipeline(\"/home/marcus/Documents/mnist/train/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Operations to the Pipeline\n",
    "\n",
    "Now that a pipeline object `p` has been created, we can add operations to the pipeline. Below we add several simple  operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p.flip_top_bottom(probability=0.1)\n",
    "p.rotate(probability=0.3, max_left_rotation=5, max_right_rotation=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can view the status of pipeline using the `status()` function, which shows information regarding the number of classes in the pipeline, the number of images, and what operations have been added to the pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operations: 2\n",
      "\t0: Flip (top_bottom_left_right=TOP_BOTTOM probability=0.1 )\n",
      "\t1: RotateRange (max_right_rotation=5.0 max_left_rotation=-5.0 probability=0.3 )\n",
      "Images: 60000\n",
      "Classes: 10\n",
      "\tClass index: 0 Class label: 0 \n",
      "\tClass index: 1 Class label: 1 \n",
      "\tClass index: 2 Class label: 2 \n",
      "\tClass index: 3 Class label: 3 \n",
      "\tClass index: 4 Class label: 4 \n",
      "\tClass index: 5 Class label: 5 \n",
      "\tClass index: 6 Class label: 6 \n",
      "\tClass index: 7 Class label: 7 \n",
      "\tClass index: 8 Class label: 8 \n",
      "\tClass index: 9 Class label: 9 \n",
      "Dimensions: 1\n",
      "\tWidth: 28 Height: 28\n",
      "Formats: 1\n",
      "\t PNG\n",
      "\n",
      "You can remove operations using the appropriate index and the remove_operation(index) function.\n"
     ]
    }
   ],
   "source": [
    "p.status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Generator\n",
    "\n",
    "A generator will create images indefinitely, and we can use this generator as input into the model created above. The generator is created with a user-defined batch size, which we define here in a variable named `batch_size`. This is used later to define number of steps per epoch, so it is best to keep it stored as a variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "g = p.keras_generator(batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The generator can now be used to created augmented data. In Python, generators are invoked using the `next()` function - the Augmentor generators will return images indefinitely, and so `next()` can be called as often as required. \n",
    "\n",
    "You can view the output of generator manually:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "images, labels = next(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Images, and their labels, are returned in batches of the size defined above by `batch_size`. The `image_batch` variable is a tuple, containing the augmentented images and their corresponding labels.\n",
    "\n",
    "To see the label of the first image returned by the generator you can use the array's index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 1 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Network\n",
    "\n",
    "We train the network by passing the generator, `g`, to the model's fit function. In Keras, if a generator is used we used the `fit_generator()` function as opposed to the standard `fit()` function. Also, the steps per epoch should roughly equal the total number of images in your dataset divided by the `batch_size`.\n",
    "\n",
    "Training the network over 5 epochs, we get the following output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "468/468 [==============================] - 33s - loss: 0.5231 - acc: 0.8358    \n",
      "Epoch 2/5\n",
      "468/468 [==============================] - 33s - loss: 0.2036 - acc: 0.9382    \n",
      "Epoch 3/5\n",
      "468/468 [==============================] - 33s - loss: 0.1610 - acc: 0.9523    \n",
      "Epoch 4/5\n",
      "468/468 [==============================] - 33s - loss: 0.1404 - acc: 0.9575    \n",
      "Epoch 5/5\n",
      "468/468 [==============================] - 34s - loss: 0.1266 - acc: 0.9616    \n"
     ]
    }
   ],
   "source": [
    "h = model.fit_generator(g, steps_per_epoch=len(p.augmentor_images)/batch_size, epochs=5, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Using Augmentor with Keras means only that you need to create a generator when you are finished creating your pipeline. This has the advantage that no images need to be saved to disk and are augmented on the fly."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
